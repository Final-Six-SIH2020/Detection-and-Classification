{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-1 Custom Object detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHqxsizCqUaP"
      },
      "source": [
        "# Installing the Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9dcNyhtBn2YU"
      },
      "source": [
        "#### Clone the repository and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAOsaaAGHxd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a1d2fb6e-c8c5-4b2d-d904-e61f92c28a7d"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KndCWKEfqldN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "311ab562-f85d-4271-c894-ee71f4b5891d"
      },
      "source": [
        "!git clone -q https://github.com/tensorflow/models.git\n",
        "!pip install -qU Cython contextlib2 pillow lxml jupyter matplotlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yOdlD0UDn9F-"
      },
      "source": [
        "#### Install the COCO API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k9it4DZsqzeb",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a402ddd0-ab22-495e-88d1-8a0d726eeb14"
      },
      "source": [
        "!git clone -q https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!make\n",
        "%cd ../../\n",
        "%cp -r cocoapi/PythonAPI/pycocotools models/research/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cocoapi' already exists and is not an empty directory.\n",
            "/content/cocoapi/PythonAPI\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.6/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/../common/maskApi.o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -o build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xbfv4BQsoS5Q"
      },
      "source": [
        "#### Protobuf Compilation and Object Detection API installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyVcTEgK4bnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "1c69004d-7060-4747-cd19-89ff17f3607a"
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "! cp object_detection/packages/tf1/setup.py .\n",
        "! python -m pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.22.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.6.0.post1)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.0.5)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.2)\n",
            "Requirement already satisfied: avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.9.2.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: grpcio<2,>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.30.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.10.1)\n",
            "Requirement already satisfied: oauth2client<4,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.5.8)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n",
            "Requirement already satisfied: fastavro<0.24,>=0.21.4 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.23.6)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.1)\n",
            "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.2)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (49.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam->object-detection==0.1) (5.4.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1534300 sha256=3d2bb9dba03e6f14d36b62af66fd8e2bf5be0b7f07c903763cd4f2e7b97873e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v1wc7rte/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gK7vHfbqrEdq",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# !wget -qnc https://github.com/protocolbuffers/protobuf/releases/download/v3.12.3/protoc-3.12.3-linux-x86_64.zip\n",
        "\n",
        "# !unzip -qq protoc-3.12.3-linux-x86_64.zip\n",
        "\n",
        "# %cp bin/protoc models/research\n",
        "# %cd models/research\n",
        "\n",
        "# import os\n",
        "# import sys\n",
        "# directory = 'object_detection/protos'\n",
        "# protoc_path = './protoc'\n",
        "# for file in os.listdir(directory):\n",
        "#     if file.endswith(\".proto\"):\n",
        "#         os.system(f\"{protoc_path} {directory}/{file} --python_out=.\")\n",
        "\n",
        "# %ls object_detection/protos/\n",
        "\n",
        "# !python setup.py build\n",
        "# !python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXn_ulrB5xWC",
        "colab_type": "text"
      },
      "source": [
        "## Set paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOWKikrAUF_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! export PYTHONPATH=$PYTHONPATH:/content/models/research\n",
        "! export PYTHONPATH=$PYTHONPATH:/content/models/research/object_detection\n",
        "! export PYTHONPATH=$PYTHONPATH:/content/models/research/slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbS-kBeW4nek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "1b5f43ea-ddd1-4e6c-9d45-2ffb920aae16"
      },
      "source": [
        "! python models/research/object_detection/builders/model_builder_tf1_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params(True)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params(True)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params(False)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_context_rcnn_from_config_with_params(False)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTF1Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTF1Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTF1Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTF1Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTF1Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTF1Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF1Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF1Test.test_session\n",
            "[ RUN      ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTF1Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTF1Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTF1Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 21 tests in 0.135s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdcY5rITWZSM",
        "colab_type": "text"
      },
      "source": [
        "# Object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGnTejqZ6khr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qU silence-tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrWUdgzczn9Z",
        "colab_type": "text"
      },
      "source": [
        "## SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuuajZP1QaHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import silence_tensorflow\n",
        "\n",
        "import object_detection\n",
        "import shutil\n",
        "import os\n",
        "import tarfile\n",
        "import six.moves.urllib as urllib\n",
        "import tensorflow as tf\n",
        "ROOT_DIR = '/content'\n",
        "\n",
        "os.chdir(ROOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gwg3QBr7I4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORKSPACE_PATH  = '/content/workspace/'\n",
        "CHECKPOINT_PATH = '/content/workspace/checkpoint'\n",
        "OUTPUT_PATH     = '/content/workspace/output'\n",
        "EXPORTED_PATH   = '/content/workspace/exported'\n",
        "ANNOTATIONS_PATH = '/content/workspace/annotations'\n",
        "IMAGES_PATH = '/content/workspace/Images'\n",
        "CONFIG_PATH = '/content/workspace/configs'\n",
        "\n",
        "LABEL_MAP_PATH      = os.path.join(WORKSPACE_PATH, 'label_map.pbtxt')\n",
        "TRAIN_CSV_PATH      = os.path.join(ANNOTATIONS_PATH, 'training.csv')\n",
        "VALID_CSV_PATH      = os.path.join(ANNOTATIONS_PATH, 'validation.csv')\n",
        "TRAIN_RECORD_PATH   = os.path.join(ANNOTATIONS_PATH, 'train.record')\n",
        "VALID_RECORD_PATH   = os.path.join(ANNOTATIONS_PATH, 'val.record')\n",
        "\n",
        "NUM_TRAIN_STEPS =  300\n",
        "\n",
        "# ---- MOBILEDET \n",
        "# MODEL_TYPE = 'ssdlite_mobiledet_cpu_320x320_coco_2020_05_19'\n",
        "# CONFIG_TYPE = 'ssdlite_mobiledet_cpu_320x320_coco_sync_4x4'\n",
        "\n",
        "# ---- MOBILENET V3 - LARGE \n",
        "# MODEL_TYPE = 'ssd_mobilenet_v3_large_coco_2020_01_14'\n",
        "# CONFIG_TYPE = 'ssdlite_mobilenet_v3_large_320x320_coco'\n",
        "\n",
        "# ---- MOBILENET V3 = SMALL \n",
        "MODEL_TYPE = 'ssd_mobilenet_v3_small_coco_2020_01_14'\n",
        "CONFIG_TYPE = 'ssdlite_mobilenet_v3_small_320x320_coco'\n",
        "\n",
        "# ---- INCEPTIONV2\n",
        "# MODEL_TYPE = 'ssd_inception_v2_coco_2018_01_28'\n",
        "# CONFIG_TYPE = 'ssd_inception_v2_coco'\n",
        "\n",
        "# ---- MOBILENET V2\n",
        "# MODEL_TYPE = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
        "# CONFIG_TYPE = 'ssd_mobilenet_v2_coco'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJnReBO4Xi44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.isdir(WORKSPACE_PATH):\n",
        "    shutil.rmtree(WORKSPACE_PATH)    \n",
        "\n",
        "os.makedirs(WORKSPACE_PATH)\n",
        "os.makedirs(OUTPUT_PATH)\n",
        "os.makedirs(EXPORTED_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfJqd8B2bjNe",
        "colab_type": "text"
      },
      "source": [
        "##  Generate tfrecords file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcIR0tx-YDnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qU googledrivedownloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGXU3f7hbn4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b4fa808a-a4fe-4612-ab2e-0911bea52746"
      },
      "source": [
        "# https://drive.google.com/file/d/1L_CvmHYL4Z8mYmJZznNDGnB9G1hYMv3P/view?usp=sharing\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1L_CvmHYL4Z8mYmJZznNDGnB9G1hYMv3P',\n",
        "                                    dest_path=f'{WORKSPACE_PATH}/SIH_COLAB.zip',\n",
        "                                    unzip=True)\n",
        "\n",
        "os.remove(f\"{WORKSPACE_PATH}/SIH_COLAB.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1L_CvmHYL4Z8mYmJZznNDGnB9G1hYMv3P into /content/workspace//SIH_COLAB.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHDjFEPlcB20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4b996ef8-e001-4cd0-82f6-a24c154e8037"
      },
      "source": [
        "! python /content/workspace/generate_tfrecords.py --csv_input={TRAIN_CSV_PATH} --output_path={TRAIN_RECORD_PATH} --img_path={IMAGES_PATH}\n",
        "! python /content/workspace/generate_tfrecords.py --csv_input={VALID_CSV_PATH} --output_path={VALID_RECORD_PATH} --img_path={IMAGES_PATH}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecords: /content/workspace/annotations/train.record\n",
            "Successfully created the TFRecords: /content/workspace/annotations/val.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7VFEajzjSj",
        "colab_type": "text"
      },
      "source": [
        "## Generate a Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18P7gvDoAf00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = {\n",
        "        1: 'Bus',\n",
        "        2: 'Car',\n",
        "        3: 'speed_sign',\n",
        "        4: 'Stop_sign',\n",
        "        5: 'Traffic_light',\n",
        "        6: 'Traffic_sign'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS-IezXhAzK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(LABEL_MAP_PATH, 'w') as f:\n",
        "    # Loop through all of the labels and write each label to the file with an id\n",
        "    for key, val in labels.items():\n",
        "        f.write('item {\\n')\n",
        "        f.write(f\"\\tid: {key}\\n\")\n",
        "        f.write(f\"\\tname: '{val}'\\n\")\n",
        "        f.write('}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06Zar0eHBGyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "fe0699d1-fcf7-41cd-c0dd-caf98a4106b5"
      },
      "source": [
        "with open(LABEL_MAP_PATH) as f:\n",
        "    print(f.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "\tid: 1\n",
            "\tname: 'Bus'\n",
            "}\n",
            "item {\n",
            "\tid: 2\n",
            "\tname: 'Car'\n",
            "}\n",
            "item {\n",
            "\tid: 3\n",
            "\tname: 'speed_sign'\n",
            "}\n",
            "item {\n",
            "\tid: 4\n",
            "\tname: 'Stop_sign'\n",
            "}\n",
            "item {\n",
            "\tid: 5\n",
            "\tname: 'Traffic_light'\n",
            "}\n",
            "item {\n",
            "\tid: 6\n",
            "\tname: 'Traffic_sign'\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba_qI2WTdCdg",
        "colab_type": "text"
      },
      "source": [
        "## Download Model and update Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFZCp8CPBhHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL\n",
        "\n",
        "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
        "model = MODEL_TYPE + '.tar.gz'\n",
        "tmp = '/content/checkpoint.tar.gz'\n",
        "\n",
        "if not os.path.exists(CHECKPOINT_PATH):\n",
        "  # Download the checkpoint\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(download_base + model, tmp)\n",
        "\n",
        "  # Extract all the `model.ckpt` files.\n",
        "  with tarfile.open(tmp) as tar:\n",
        "    for member in tar.getmembers():\n",
        "      member.name = os.path.basename(member.name)\n",
        "      if 'model.ckpt' in member.name:\n",
        "        tar.extract(member, path=CHECKPOINT_PATH)\n",
        "\n",
        "  os.remove(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "annilzUwii6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "f5083289-6d05-43bc-f392-6a20c81c0a7c"
      },
      "source": [
        "# CONFIG\n",
        "\n",
        "import re\n",
        "from google.protobuf import text_format\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "\n",
        "pipeline_skeleton = f'{CONFIG_PATH}/{CONFIG_TYPE}.config'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_skeleton)\n",
        "\n",
        "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "num_classes = len(labels.keys())\n",
        "meta_arch = configs[\"model\"].WhichOneof(\"model\")\n",
        "\n",
        "override_dict = {\n",
        "  'model.{}.num_classes'.format(meta_arch): num_classes,\n",
        "  'train_config.batch_size': 24,\n",
        "  'train_input_path': TRAIN_RECORD_PATH,\n",
        "  'eval_input_path': VALID_RECORD_PATH,\n",
        "  'train_config.fine_tune_checkpoint': os.path.join(CHECKPOINT_PATH, 'model.ckpt'),\n",
        "  'label_map_path': LABEL_MAP_PATH\n",
        "}\n",
        "\n",
        "print(num_classes)\n",
        "configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n",
        "pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n",
        "config_util.save_pipeline_config(pipeline_config, WORKSPACE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "INFO:tensorflow:Maybe overwriting model.ssd.num_classes: 6\n",
            "INFO:tensorflow:Maybe overwriting train_config.batch_size: 24\n",
            "INFO:tensorflow:Maybe overwriting train_input_path: /content/workspace/annotations/train.record\n",
            "INFO:tensorflow:Maybe overwriting eval_input_path: /content/workspace/annotations/val.record\n",
            "INFO:tensorflow:Maybe overwriting train_config.fine_tune_checkpoint: /content/workspace/checkpoint/model.ckpt\n",
            "INFO:tensorflow:Maybe overwriting label_map_path: /content/workspace/label_map.pbtxt\n",
            "INFO:tensorflow:Writing pipeline config file to /content/workspace/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeEZkHme2g4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(f'{WORKSPACE_PATH}/pipeline.config') as f:\n",
        "#     print(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOazDael2C43",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05VK__-y86f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15d4a090-93d0-4a49-b4dc-c06d27899d8a"
      },
      "source": [
        "! rm -rf {OUTPUT_PATH}\n",
        "!python -m object_detection.model_main \\\n",
        "    --pipeline_config_path=$WORKSPACE_PATH/pipeline.config \\\n",
        "    --model_dir=$OUTPUT_PATH \\\n",
        "    --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "    --num_eval_steps=2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0721 18:02:58.249024 139893223167872 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 300\n",
            "I0721 18:02:58.249376 139893223167872 config_util.py:552] Maybe overwriting train_steps: 300\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0721 18:02:58.249559 139893223167872 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0721 18:02:58.249648 139893223167872 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0721 18:02:58.249740 139893223167872 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0721 18:02:58.249840 139893223167872 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0721 18:02:58.249952 139893223167872 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/workspace/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3b0859ec88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0721 18:02:58.250373 139893223167872 estimator.py:212] Using config: {'_model_dir': '/content/workspace/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3b0859ec88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f3b085b41e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0721 18:02:58.251106 139893223167872 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f3b085b41e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0721 18:02:58.251919 139893223167872 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0721 18:02:58.252218 139893223167872 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0721 18:02:58.252572 139893223167872 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0721 18:02:58.257531 139893223167872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0721 18:02:58.286868 139893223167872 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0721 18:02:58.292502 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0721 18:02:58.312842 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f3b085adb70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0721 18:02:58.342717 139893223167872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f3b085adb70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f3b2ae9d950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0721 18:02:58.508859 139893223167872 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f3b2ae9d950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0721 18:02:58.514105 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0721 18:02:58.520642 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0721 18:02:58.598156 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0721 18:02:59.386135 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0721 18:02:59.805389 139893223167872 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0721 18:02:59.817563 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:03:01.895561 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:03:01.973024 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:03:02.050811 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:03:02.140822 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:03:02.224145 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:03:02.427851 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0721 18:03:09.062235 139893223167872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0721 18:03:09.063553 139893223167872 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0721 18:03:11.311074 139893223167872 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-21 18:03:11.311449: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-21 18:03:11.315710: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000144999 Hz\n",
            "2020-07-21 18:03:11.315891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1282aa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-21 18:03:11.315922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-21 18:03:11.317714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-21 18:03:11.390707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:03:11.391248: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12828540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-21 18:03:11.391285: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-07-21 18:03:11.391470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:03:11.391826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:03:11.392162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:03:11.393529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:03:11.395003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:03:11.395343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:03:11.396790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:03:11.397470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:03:11.400158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:03:11.400288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:03:11.400679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:03:11.400993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:03:11.401056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:03:11.402044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:03:11.402069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:03:11.402079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:03:11.402193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:03:11.402571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:03:11.402902: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-21 18:03:11.402943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0721 18:03:13.709474 139893223167872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0721 18:03:13.927943 139893223167872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/workspace/output/model.ckpt.\n",
            "I0721 18:03:20.042135 139893223167872 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/workspace/output/model.ckpt.\n",
            "2020-07-21 18:03:26.553702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:03:28.061505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 77.043175, step = 0\n",
            "I0721 18:03:30.161047 139893223167872 basic_session_run_hooks.py:262] loss = 77.043175, step = 0\n",
            "INFO:tensorflow:global_step/sec: 3.97432\n",
            "I0721 18:03:55.321653 139893223167872 basic_session_run_hooks.py:692] global_step/sec: 3.97432\n",
            "INFO:tensorflow:loss = 3.9556007, step = 100 (25.162 sec)\n",
            "I0721 18:03:55.322940 139893223167872 basic_session_run_hooks.py:260] loss = 3.9556007, step = 100 (25.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.71838\n",
            "I0721 18:04:16.515352 139893223167872 basic_session_run_hooks.py:692] global_step/sec: 4.71838\n",
            "INFO:tensorflow:loss = 3.6041632, step = 200 (21.194 sec)\n",
            "I0721 18:04:16.516525 139893223167872 basic_session_run_hooks.py:260] loss = 3.6041632, step = 200 (21.194 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 300 into /content/workspace/output/model.ckpt.\n",
            "I0721 18:04:37.786193 139893223167872 basic_session_run_hooks.py:606] Saving checkpoints for 300 into /content/workspace/output/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f3b0271fe10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0721 18:04:38.832410 139893223167872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f3b0271fe10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f3b027e5ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0721 18:04:38.997155 139893223167872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f3b027e5ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0721 18:04:39.487064 139893223167872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:41.385219 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:41.467718 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:41.536736 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:41.608373 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:41.676335 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:41.745422 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0721 18:04:42.471011 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0721 18:04:42.653210 139893223167872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0721 18:04:43.144961 139893223167872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-21T18:04:43Z\n",
            "I0721 18:04:43.159805 139893223167872 evaluation.py:255] Starting evaluation at 2020-07-21T18:04:43Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0721 18:04:43.584830 139893223167872 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-21 18:04:43.585898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:43.586276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:04:43.586371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:04:43.586399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:04:43.586423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:04:43.586445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:04:43.586465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:04:43.586485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:04:43.586506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:04:43.586591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:43.586959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:43.587249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:04:43.587294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:04:43.587307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:04:43.587317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:04:43.587410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:43.587916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:43.588371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "I0721 18:04:43.589762 139893223167872 saver.py:1284] Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0721 18:04:44.501297 139893223167872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0721 18:04:44.638390 139893223167872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 274 images.\n",
            "I0721 18:04:53.915462 139889721771776 coco_evaluation.py:237] Performing evaluation on 274 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0721 18:04:53.917973 139889721771776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0721 18:04:53.937257 139889721771776 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.88s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.31s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-21-18:04:55\n",
            "I0721 18:04:55.240344 139893223167872 evaluation.py:275] Finished evaluation at 2020-07-21-18:04:55\n",
            "INFO:tensorflow:Saving dict for global step 300: DetectionBoxes_Precision/mAP = 0.0037502588, DetectionBoxes_Precision/mAP (large) = 0.008552713, DetectionBoxes_Precision/mAP (medium) = 0.0031353135, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.008156648, DetectionBoxes_Precision/mAP@.75IOU = 0.003178428, DetectionBoxes_Recall/AR@1 = 0.044298757, DetectionBoxes_Recall/AR@10 = 0.08832139, DetectionBoxes_Recall/AR@100 = 0.10954825, DetectionBoxes_Recall/AR@100 (large) = 0.25385192, DetectionBoxes_Recall/AR@100 (medium) = 0.0032258064, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 2.6750445, Loss/localization_loss = 1.1654748, Loss/regularization_loss = 1.5945973, Loss/total_loss = 5.435115, global_step = 300, learning_rate = 0.1733305, loss = 5.435115\n",
            "I0721 18:04:55.240617 139893223167872 estimator.py:2049] Saving dict for global step 300: DetectionBoxes_Precision/mAP = 0.0037502588, DetectionBoxes_Precision/mAP (large) = 0.008552713, DetectionBoxes_Precision/mAP (medium) = 0.0031353135, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.008156648, DetectionBoxes_Precision/mAP@.75IOU = 0.003178428, DetectionBoxes_Recall/AR@1 = 0.044298757, DetectionBoxes_Recall/AR@10 = 0.08832139, DetectionBoxes_Recall/AR@100 = 0.10954825, DetectionBoxes_Recall/AR@100 (large) = 0.25385192, DetectionBoxes_Recall/AR@100 (medium) = 0.0032258064, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 2.6750445, Loss/localization_loss = 1.1654748, Loss/regularization_loss = 1.5945973, Loss/total_loss = 5.435115, global_step = 300, learning_rate = 0.1733305, loss = 5.435115\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: /content/workspace/output/model.ckpt-300\n",
            "I0721 18:04:55.952399 139893223167872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 300: /content/workspace/output/model.ckpt-300\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0721 18:04:55.953133 139893223167872 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0721 18:04:56.181977 139893223167872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:58.234382 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:58.306857 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:58.377504 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:58.445553 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:58.518226 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:04:58.586324 139893223167872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0721 18:04:59.145395 139893223167872 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0721 18:04:59.145679 139893223167872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0721 18:04:59.146298 139893223167872 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0721 18:04:59.146410 139893223167872 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0721 18:04:59.146491 139893223167872 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0721 18:04:59.146561 139893223167872 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0721 18:04:59.146624 139893223167872 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-07-21 18:04:59.147168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:59.147529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:04:59.147616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:04:59.147640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:04:59.147662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:04:59.147683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:04:59.147706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:04:59.147726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:04:59.147745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:04:59.147831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:59.148201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:59.148479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:04:59.148521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:04:59.148535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:04:59.148544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:04:59.148636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:59.148967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:04:59.149278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "I0721 18:04:59.151454 139893223167872 saver.py:1284] Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0721 18:04:59.625502 139893223167872 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0721 18:04:59.625722 139893223167872 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/workspace/output/export/Servo/temp-b'1595354695'/saved_model.pb\n",
            "I0721 18:05:00.387650 139893223167872 builder_impl.py:425] SavedModel written to: /content/workspace/output/export/Servo/temp-b'1595354695'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 3.8200257.\n",
            "I0721 18:05:00.626375 139893223167872 estimator.py:371] Loss for final step: 3.8200257.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dwLqV669PvC",
        "colab_type": "text"
      },
      "source": [
        "## Export graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NUxBYo92U_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e32f86f4-9704-4c63-8b5e-7ce4c35d6b90"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "regex = re.compile(r\"model\\.ckpt-([0-9]+)\\.index\")\n",
        "numbers = [int(regex.search(f).group(1)) for f in os.listdir(OUTPUT_PATH) if regex.search(f)]\n",
        "TRAINED_CHECKPOINT_PREFIX = os.path.join(OUTPUT_PATH, 'model.ckpt-{}'.format(max(numbers)))\n",
        "\n",
        "print(f'Using {TRAINED_CHECKPOINT_PREFIX}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using /content/workspace/output/model.ckpt-300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp8btNy0v7C-",
        "colab_type": "text"
      },
      "source": [
        "## Frozen inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fSpIv3K9Rwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43a9dded-5927-41c6-fd95-0f942fa9fb8f"
      },
      "source": [
        "!rm -rf $EXPORTED_PATH\n",
        "\n",
        "!python -m object_detection.export_inference_graph \\\n",
        "  --pipeline_config_path=$WORKSPACE_PATH/pipeline.config \\\n",
        "  --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n",
        "  --output_directory=$EXPORTED_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0721 18:05:09.358046 140676600416128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:11.154951 140676600416128 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:11.234031 140676600416128 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:11.411270 140676600416128 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:11.484710 140676600416128 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:11.560396 140676600416128 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:11.640858 140676600416128 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/post_processing.py:1108: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0721 18:05:11.889917 140676600416128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/post_processing.py:1108: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0721 18:05:12.150964 140676600416128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0721 18:05:12.154083 140676600416128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0721 18:05:12.154644 140676600416128 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "206 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/964.17k params)\n",
            "  BoxPredictor_0 (--/14.72k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/3.47k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x288x12, 3.46k/3.46k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/6.07k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (21, 21/21 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x288x21, 6.05k/6.05k params)\n",
            "    BoxPredictor_0/ClassPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "  BoxPredictor_1 (--/24.26k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/6.94k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x288x24, 6.91k/6.91k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/12.14k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (42, 42/42 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x288x42, 12.10k/12.10k params)\n",
            "    BoxPredictor_1/ClassPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "  BoxPredictor_2 (--/43.07k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/21.55k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (42, 42/42 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x42, 21.50k/21.50k params)\n",
            "    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "  BoxPredictor_3 (--/21.57k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/10.79k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (42, 42/42 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x42, 10.75k/10.75k params)\n",
            "    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_4 (--/21.57k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/10.79k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (42, 42/42 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x42, 10.75k/10.75k params)\n",
            "    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_5 (--/10.82k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/5.42k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (42, 42/42 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x42, 5.38k/5.38k params)\n",
            "    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "  FeatureExtractor (--/828.16k params)\n",
            "    FeatureExtractor/MobilenetV3 (--/828.16k params)\n",
            "      FeatureExtractor/MobilenetV3/Conv (--/432 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/weights (3x3x3x16, 432/432 params)\n",
            "      FeatureExtractor/MobilenetV3/Conv_1 (--/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv (--/680 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/depthwise (--/144 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/depthwise_weights (3x3x16x1, 144/144 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/project (--/256 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/weights (1x1x16x16, 256/256 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite (--/280 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv (--/136 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv/biases (8, 8/8 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv/weights (1x1x16x8, 128/128 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1 (--/144 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/biases (16, 16/16 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/weights (1x1x8x16, 128/128 params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_1 (--/3.53k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise (--/648 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/depthwise_weights (3x3x72x1, 648/648 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/expand (--/1.15k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/weights (1x1x16x72, 1.15k/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/project (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/weights (1x1x72x24, 1.73k/1.73k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_10 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_2 (--/5.02k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise (--/792 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/depthwise_weights (3x3x88x1, 792/792 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/expand (--/2.11k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/weights (1x1x24x88, 2.11k/2.11k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/project (--/2.11k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/weights (1x1x88x24, 2.11k/2.11k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_3 (--/13.27k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise (--/2.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/depthwise_weights (5x5x96x1, 2.40k/2.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/expand (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/weights (1x1x24x96, 2.30k/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/project (--/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/weights (1x1x96x40, 3.84k/3.84k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite (--/4.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv (--/2.33k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/biases (24, 24/24 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1 (--/2.40k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/biases (96, 96/96 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/weights (1x1x24x96, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_4 (--/56.22k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise (--/6.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/depthwise_weights (5x5x240x1, 6.00k/6.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/project (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/weights (1x1x240x40, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite (--/31.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv (--/15.42k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/biases (64, 64/64 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/weights (1x1x240x64, 15.36k/15.36k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1 (--/15.60k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/biases (240, 240/240 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/weights (1x1x64x240, 15.36k/15.36k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_5 (--/56.22k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise (--/6.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/depthwise_weights (5x5x240x1, 6.00k/6.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/project (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/weights (1x1x240x40, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite (--/31.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv (--/15.42k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/biases (64, 64/64 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/weights (1x1x240x64, 15.36k/15.36k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1 (--/15.60k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/biases (240, 240/240 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/weights (1x1x64x240, 15.36k/15.36k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_6 (--/21.39k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise (--/3.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/expand (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/weights (1x1x40x120, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/project (--/5.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/weights (1x1x120x48, 5.76k/5.76k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite (--/7.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv (--/3.87k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv/biases (32, 32/32 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1 (--/3.96k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_7 (--/29.13k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise (--/3.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/depthwise_weights (5x5x144x1, 3.60k/3.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/expand (--/6.91k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/weights (1x1x48x144, 6.91k/6.91k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/project (--/6.91k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/weights (1x1x144x48, 6.91k/6.91k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite (--/11.70k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv (--/5.80k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv/biases (40, 40/40 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv/weights (1x1x144x40, 5.76k/5.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1 (--/5.90k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/biases (144, 144/144 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/weights (1x1x40x144, 5.76k/5.76k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_8 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_9 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256/weights (1x1x288x256, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "\n",
            "======================End of Report==========================\n",
            "206 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/28.89k flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_2 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.20k/1.20k flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_2 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_3 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_2 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_1 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/GreaterEqual (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_3 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_2 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_3 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_1 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/mul (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub_1 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_6 (600/600 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Sum (599/599 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_3 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_2 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_2 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_1 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_1 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_3 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_4 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_5 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_5 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_4 (100/100 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2020-07-21 18:05:13.963126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-21 18:05:13.966518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:13.966902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:13.967227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:13.968660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:13.970406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:13.970708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:13.972429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:13.973497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:13.977168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:13.977279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:13.977678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:13.978002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:13.978300: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-21 18:05:13.982892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000144999 Hz\n",
            "2020-07-21 18:05:13.983058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c4abc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-21 18:05:13.983084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-21 18:05:14.060936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:14.061437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c4ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-21 18:05:14.061466: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-07-21 18:05:14.061632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:14.061976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:14.062038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:14.062063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:14.062085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:14.062106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:14.062155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:14.062175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:14.062196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:14.062284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:14.062683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:14.063017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:14.063080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:14.064050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:05:14.064077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:05:14.064087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:05:14.064213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:14.064594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:14.064920: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-21 18:05:14.064957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "I0721 18:05:14.066686 140676600416128 saver.py:1284] Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0721 18:05:15.602369 140676600416128 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-07-21 18:05:16.069889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:16.070329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:16.070416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:16.070440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:16.070461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:16.070481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:16.070500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:16.070519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:16.070539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:16.070619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:16.071005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:16.071340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:16.071382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:05:16.071397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:05:16.071406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:05:16.071511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:16.071886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:16.072243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "I0721 18:05:16.073666 140676600416128 saver.py:1284] Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0721 18:05:16.645093 140676600416128 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0721 18:05:16.645375 140676600416128 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 350 variables.\n",
            "I0721 18:05:16.984896 140676600416128 graph_util_impl.py:334] Froze 350 variables.\n",
            "INFO:tensorflow:Converted 350 variables to const ops.\n",
            "I0721 18:05:17.038105 140676600416128 graph_util_impl.py:394] Converted 350 variables to const ops.\n",
            "2020-07-21 18:05:17.134839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:17.135292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:17.135382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:17.135407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:17.135429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:17.135449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:17.135468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:17.135487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:17.135507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:17.135592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:17.135976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:17.136301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:17.136341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:05:17.136356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:05:17.136365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:05:17.136459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:17.136841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:17.137169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0721 18:05:17.606730 140676600416128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0721 18:05:17.607421 140676600416128 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0721 18:05:17.607562 140676600416128 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/workspace/exported/saved_model/saved_model.pb\n",
            "I0721 18:05:17.799375 140676600416128 builder_impl.py:425] SavedModel written to: /content/workspace/exported/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/workspace/exported/pipeline.config\n",
            "I0721 18:05:17.817308 140676600416128 config_util.py:254] Writing pipeline config file to /content/workspace/exported/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YP2sQYO5-Wb",
        "colab_type": "text"
      },
      "source": [
        "## Frozen tflite graph and conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqDIPK6WMHyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19a64f63-190c-4ac6-cd80-c0b4ab00e7f4"
      },
      "source": [
        "!rm -rf tflite_graph\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "    --pipeline_config_path={WORKSPACE_PATH}/pipeline.config \\\n",
        "    --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n",
        "    --output_directory=$WORKSPACE_PATH/tflite_graph \\\n",
        "    --add_postprocessing_op=true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0721 18:05:26.081302 140371960784768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:27.876163 140371960784768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:27.944872 140371960784768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:28.017526 140371960784768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:28.184422 140371960784768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:28.253882 140371960784768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0721 18:05:28.327196 140371960784768 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "2020-07-21 18:05:28.408702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-21 18:05:28.412386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.412793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:28.413069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:28.414633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:28.416375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:28.416716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:28.418545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:28.419452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:28.423044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:28.423206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.423624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.423962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:28.424246: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-21 18:05:28.429457: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000144999 Hz\n",
            "2020-07-21 18:05:28.429659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e60bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-21 18:05:28.429690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-21 18:05:28.510870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.511525: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e60a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-21 18:05:28.511565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-07-21 18:05:28.511777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.512222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:28.512317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:28.512351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:28.512384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:28.512426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:28.512445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:28.512472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:28.512498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:28.512590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.512992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.513355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:28.513427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:28.514443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:05:28.514473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:05:28.514487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:05:28.514626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.515028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:28.515407: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-21 18:05:28.515455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0721 18:05:28.920386 140371960784768 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-07-21 18:05:29.311084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:29.311596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-21 18:05:29.311700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-21 18:05:29.311732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-21 18:05:29.311753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-21 18:05:29.311777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-21 18:05:29.311805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-21 18:05:29.311828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-21 18:05:29.311851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-21 18:05:29.311949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:29.312467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:29.312841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-21 18:05:29.312883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-21 18:05:29.312921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-21 18:05:29.312931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-21 18:05:29.313025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:29.313457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-21 18:05:29.313835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7024 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "I0721 18:05:29.314957 140371960784768 saver.py:1284] Restoring parameters from /content/workspace/output/model.ckpt-300\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0721 18:05:30.325152 140371960784768 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0721 18:05:30.325433 140371960784768 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 350 variables.\n",
            "I0721 18:05:30.624661 140371960784768 graph_util_impl.py:334] Froze 350 variables.\n",
            "INFO:tensorflow:Converted 350 variables to const ops.\n",
            "I0721 18:05:30.659138 140371960784768 graph_util_impl.py:394] Converted 350 variables to const ops.\n",
            "2020-07-21 18:05:30.722469: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeFGtq2rtLvv",
        "colab_type": "text"
      },
      "source": [
        " The outputs of the quantized model represents four arrays, named:\n",
        " * TFLite_Detetion_PostProcess    -> detection_boxes\n",
        " * TFLite_Detection_PostProcess:1 -> detection_classes\n",
        " * TFLite_Detection_PostProcess:2 -> detection_scores\n",
        " * TFLite_Detection_PostProcess:3 -> num_detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PNiKlPKoTx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e3a815c0-2750-4f30-b373-a9d50f145629"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_frozen_graph('/content/workspace/tflite_graph/tflite_graph.pb', \n",
        "                                                      input_shapes = {'normalized_input_image_tensor':(1,320,320, 3)},\n",
        "                                                      input_arrays = ['normalized_input_image_tensor'],\n",
        "                                                      output_arrays = ['TFLite_Detection_PostProcess',\n",
        "                                                                       'TFLite_Detection_PostProcess:1',\n",
        "                                                                       'TFLite_Detection_PostProcess:2',\n",
        "                                                                       'TFLite_Detection_PostProcess:3']) \n",
        "converter.allow_custom_ops=True \n",
        "# converter.target_ops = [\n",
        "#                         tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "#                         tf.lite.OpsSet.SELECT_TF_OPS,\n",
        "\n",
        "# ]\n",
        "converter.optimizations = [\n",
        "                        #    tf.lite.Optimize.DEFAULT,\n",
        "                        #    tf.lite.Optimize.OPTIMIZE_FOR_SIZE,\n",
        "                        #    tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "                           ]\n",
        "tflite_model = converter.convert() \n",
        "\n",
        "tf_model_files = f'/content/workspace/{CONFIG_TYPE}.tflite' \n",
        "!rm -rf $tf_model_files\n",
        "open(tf_model_files,\"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3991484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpKjgpDg8Nr3",
        "colab_type": "text"
      },
      "source": [
        "# Test the Model with TFLite Interpreter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOy8xBbVDoPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdmzTelD6ZMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get model details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0][\"shape\"][1]\n",
        "width = input_details[0][\"shape\"][2]\n",
        "\n",
        "floating_model = input_details[0][\"dtype\"] == np.float32\n",
        "\n",
        "input_mean = 127.5\n",
        "input_std = 127.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "falNxy8a_Dda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "52c496d1-af77-4a37-de19-11f692bb9f95"
      },
      "source": [
        "print(input_details[0][\"dtype\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG4RLm0M6ZOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddNJ_XnX6ZR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}